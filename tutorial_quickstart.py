# -*- coding: utf-8 -*-
"""tutorial-quickstart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/adap/flower/blob/main/datasets/docs/source/tutorial-quickstart.ipynb

# Quickstart

Start with `Flower Datasets` as fast as possible by learning the essentials.

## Install Flower Datasets
"""



from flwr_datasets import FederatedDataset

fds = FederatedDataset(dataset="albertvillanova/medmnist-v2",
                       subset="bloodmnist",
                       partitioners={"train": 200})
partition = fds.load_partition(0, "train")
centralized_dataset = fds.load_split("test")

partition.features

from torchvision.transforms import Compose, Normalize, ToTensor, Grayscale, Resize
def apply_transforms_0(batch: dict) -> dict:
    transform = Compose([
        ToTensor(),
    ])
    batch["image"] = [transform(img) for img in batch["image"]]
    return batch



# Transformation to convert images to tensors and apply normalization
def apply_transforms(batch: dict) -> dict:
    """
    Apply transformations to the batch of images, including resizing, grayscale conversion,
    tensor conversion, and normalization.

    Args:
        batch (dict): Batch of images and labels where 'image' is a list of images.

    Returns:
        dict: Batch with transformed images.
    """
    transform = Compose([
        Resize((224, 224)),
        #Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels
        ToTensor(),
        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet mean and std normalization
    ])

    # Apply transformations
    #print("image type=================", type(batch["image"]))
    batch["image"] = [transform(img) for img in batch["image"]]
    return batch

from torch.utils.data import DataLoader
partition_torch = partition.with_transform(apply_transforms_0)
# Now, you can check if you didn't make any mistakes by calling partition_torch[0]
dataloader = DataLoader(partition_torch, batch_size=64)

from abc import ABC, abstractmethod
import torch
from torch import nn
import numpy as np

class Attack(ABC):
    """
    A generic interface for attack
    """

    def on_batch_selection(self, net: nn.Module, device: str, inputs: torch.Tensor, targets: torch.Tensor):

        return inputs, targets

    def on_before_backprop(self, model, loss):
        return model, loss

    def on_after_backprop(self, model, loss):
        return model, loss

    def on_dataset_load(self, trainset, valset):
        return trainset, valset

class Benin(Attack):
    def on_batch_selection(self, net: nn.Module, device: str, inputs: torch.Tensor, targets: torch.Tensor):
        return inputs, targets

    def on_before_backprop(self, model, loss):
        return model, loss

    def on_after_backprop(self, model, loss):
        return model, loss



class Noops(Attack):
    def on_batch_selection(self, net: nn.Module, device: str, inputs: torch.Tensor, targets: torch.Tensor):
        return inputs, targets

    def on_before_backprop(self, model, loss):
        return model, loss

    def on_after_backprop(self, model, loss):
        return model, loss

    def on_dataset_load(self, trainset, valset):
        return trainset, valset

class AutoRegressorAttack(Attack):

    def __init__(self, config):
        super().__init__()

        # TODO check the number of channels
        self.num_channels = 3

        self.num_classes = int(config.model.num_classes)
        self.epsilon = float(config.poisoning.epsilon)
        self.size = tuple(config.poisoning.size)

        self.crop = int(config.poisoning.crop)
        self.gaussian_noise = bool(config.poisoning.gaussian_noise)

        if self.size is None:
            self.size = (36,36)

        if self.crop is None:
            self.crop = 3

        if self.gaussian_noise is None:
            self.gaussian_noise = False

        if self.epsilon is None:
            self.epsilon = 8/255

        self.ar_params = get_ar_params(num_classes=self.num_classes)
        self.ar_params = [torch.clamp(param, -1, 1) for param in self.ar_params]
        self.ar_params *= 255
        print(self.crop, self.size, self.gaussian_noise,self.epsilon,self.num_channels,self.num_classes)

    # Preprocess the dataset and store modified items
    def preprocess_dataset(dataset, modify_fn):
        modified_data = []
        for item in dataset:
            modified_data.append(modify_fn(item))
        return modified_data

    def generate(self, index, p=np.inf, shift_x=0, shift_y=0):
        start_signal = torch.randn((self.num_channels, self.size[0], self.size[1]))
        kernel_size = 3
        rows_to_update = self.size[0] - kernel_size + 1
        cols_to_update = self.size[1] - kernel_size + 1
        ar_param = self.ar_params[index]
        ar_coeff = ar_param.unsqueeze(dim=1)

        for i in range(rows_to_update):
            for j in range(cols_to_update):
                val = torch.nn.functional.conv2d(
                    start_signal[:, i: i + kernel_size, j: j + kernel_size],
                    ar_coeff,
                    groups=self.num_channels,
                )#.clamp(-1,1)
                noise = torch.randn(1) if self.gaussian_noise else 0
                start_signal[:, i + kernel_size - 1, j + kernel_size - 1] = (
                        val.squeeze() + noise
                )
        start_signal_crop = start_signal[:, self.crop:, self.crop:]
        generated_norm = torch.norm(start_signal_crop, p=p, dim=(0, 1, 2))
        scale = (1 / generated_norm) * self.epsilon
        start_signal_crop = scale * start_signal_crop
        shifted_signal = torch.roll(start_signal_crop, shifts=(shift_y, shift_x), dims=(1, 2))

        return start_signal_crop, generated_norm, shifted_signal

    def on_dataset_load(self, trainset, valset):
        def show_images(original, attacked, title=""):
            fig, axes = plt.subplots(1, 2, figsize=(10, 5))

            axes[0].imshow(original.permute(1, 2, 0))  # Convert CHW to HWC
            axes[0].set_title("Original")
            axes[0].axis("off")

            axes[1].imshow(attacked.permute(1, 2, 0))  # Convert CHW to HWC
            axes[1].set_title("Attacked")
            axes[1].axis("off")

            plt.suptitle(title)
            plt.show()

        new_train = trainset.with_transform(apply_transforms_0)

        def apply_modifications(item):
            old_image = item["image"]
            label = item["label"]

            delta, _, delta2 = self.generate(p=2, index=label, shift_x=17, shift_y=17)
            modified_image = old_image + delta2

            return {"image": modified_image, "label": label}

        # Preprocess the trainset
        modified_trainset = []
        for item in new_train:
            modified_item = apply_modifications(item)
            modified_trainset.append(modified_item)

        # Replace the original trainset's data with the modified data
        trainset.data = [item["image"] for item in modified_trainset]
        trainset.targets = [item["label"] for item in modified_trainset]
        trainset = trainset.with_transform(revert_transforms)
        return trainset, valset

        #modified_trainset = new_train.map(apply_modifications)

        #print(modified_trainset, modified_trainset.__class__.__name__)  # Should be same as before
        # Revert `ToTensor` transformation
        # modified_trainset = modified_trainset.with_transform(revert_transforms)
        # print("passsssssssssssssssssssssssssssssssssssss")
        #return modified_trainset, valset


    def on_batch_selection(self, net, device: str, inputs: torch.Tensor,targets: torch.Tensor):
        return inputs, targets

    def on_before_backprop(self, model, loss):
        return model, loss

    def on_after_backprop(self, model, gradients):
        return gradients

import os
import random

import numpy as np
import torch

def get_ar_params(num_classes, file_path=None):
    """
    Load AR parameter lists from 'file_path' if it exists,
    otherwise generate them randomly and save.

    Generate 3*3*3 kernels for each class.
    """
    #TODO add seed param for reproducibility
    if file_path is None or not os.path.exists(file_path) :
        b_list = []
        for _ in range(num_classes):
            b = torch.randn((3, 3, 3))
            for c in range(3):
                b[c][2][2] = 0
                b[c] /= torch.sum(b[c])
            b_list.append(b.numpy())
    else:
        data = np.load(file_path, allow_pickle=True)
        b_list = data["b_list"]  # This should be a numpy object array
        print(f"Loaded AR parameters from {file_path}")



    b_list = torch.tensor(b_list).float()

    return b_list



from torchvision.transforms.functional import to_pil_image

def revert_transforms(batch: dict) -> dict:
    # Convert tensors back to PIL images
    batch["image"] = [to_pil_image(tensor) for tensor in batch["image"]]
    return batch

from matplotlib import pyplot as plt

size = (36,36)



crop = 3


gaussian_noise = False

epsilon = 8/255

ar_params = get_ar_params(num_classes=8)
ar_params = [torch.clamp(param, -1, 1) for param in ar_params]
ar_params *= 255

def generate(index, p=np.inf, shift_x=0, shift_y=0):
    start_signal = torch.randn((3, size[0], size[1]))
    kernel_size = 3
    rows_to_update = size[0] - kernel_size + 1
    cols_to_update = size[1] - kernel_size + 1
    ar_param = ar_params[index]
    ar_coeff = ar_param.unsqueeze(dim=1)

def on_dataset_load(trainset, valset):
        def show_images(original, attacked, title=""):
            fig, axes = plt.subplots(1, 2, figsize=(10, 5))

            axes[0].imshow(original.permute(1, 2, 0))  # Convert CHW to HWC
            axes[0].set_title("Original")
            axes[0].axis("off")

            axes[1].imshow(attacked.permute(1, 2, 0))  # Convert CHW to HWC
            axes[1].set_title("Attacked")
            axes[1].axis("off")

            plt.suptitle(title)
            plt.show()

        new_train = trainset.with_transform(apply_transforms_0)

        def apply_modifications(item):
            old_image = item["image"]
            label = item["label"]

            delta, _, delta2 = generate(p=2, index=label, shift_x=17, shift_y=17)
            modified_image = old_image + delta2

            return {"image": modified_image, "label": label}

        # Preprocess the trainset
        modified_trainset = []
        for item in new_train:
            modified_item = apply_modifications(item)
            modified_trainset.append(modified_item)

        # Replace the original trainset's data with the modified data
        trainset.data = [item["image"] for item in modified_trainset]
        trainset.targets = [item["label"] for item in modified_trainset]
        trainset = trainset.with_transform(revert_transforms)
        return trainset, valset

trainset = on_dataset_load(partition, partition)

"""If you want to use audio datasets install:

```bash
! pip install -q "flwr-datasets[audio]"
```

## Choose the dataset

To choose the dataset, go to Hugging Face [Datasets Hub](https://huggingface.co/datasets) and search for your dataset by name. You will pass that names to the `dataset` parameter of `FederatedDataset`. Note that the name is case-sensitive.

<div style="max-width:80%; margin-left: auto; margin-right: auto;">
  <img src="https://github.com/adap/flower/blob/main/datasets/docs/source/_static/tutorial-quickstart/choose-hf-dataset.png?raw=1" alt="Choose HF dataset."/>
</div>

Note that once the dataset is available on HuggingFace Hub it can be immediately used in `Flower Datasets` (no approval from Flower team is needed, no custom code needed).

Here is how it looks for `CIFAR10` dataset.

<div style="max-width:80%; margin-left: auto; margin-right: auto;">
  <img src="https://github.com/adap/flower/blob/main/datasets/docs/source/_static/tutorial-quickstart/copy-dataset-name.png?raw=1" alt="Choose HF dataset."/>
</div>

## Partition the dataset

To partition a dataset (in a basic scenario), you need to choose two things:
1) A dataset (identified by a name),
2) A partitioning scheme (by selecting one of the supported partitioning schemes, [see all of them here](https://flower.ai/docs/datasets/ref-api/flwr_datasets.partitioner.html), or creating a custom partitioning scheme).



**1) Dataset choice**

We will pass the name of the dataset to `FederatedDataset(dataset="some-name", other-parameters)`. In this example it will be: `FederatedDataset(dataset="uoft-cs/cifar10", other-parameters)`

**2) Partitioner choice**

We will partition the dataset in an IID manner using `IidPartitioner` ([link to the docs](https://flower.ai/docs/datasets/ref-api/flwr_datasets.partitioner.IidPartitioner.html#flwr_datasets.partitioner.IidPartitioner)).
Only the train split of the dataset will be processed. In general, we do `FederatedDataset(dataset="some-name", partitioners={"split-name": partitioning_scheme})`, which for this example looks like:
"""

from flwr_datasets import FederatedDataset
from flwr_datasets.partitioner import IidPartitioner

fds = FederatedDataset(
    dataset="uoft-cs/cifar10", partitioners={"train": IidPartitioner(num_partitions=10)}
)

# Load the first partition of the "train" split
partition = fds.load_partition(0, "train")
# You can access the whole "test" split of the base dataset (it hasn't been partitioned)
centralized_dataset = fds.load_split("test")

"""Now we have 10 partitions created from the train split of the CIFAR10 dataset and the test split
for the centralized evaluation. Later we will convert the type of the dataset from Hugging Face's `Dataset` type to the format required by PyTorch/TensorFlow frameworks.

## Investigate the partition

### Features

Now we will determine the names of the features of your dataset (you can alternatively do that directly on the Hugging Face
website). The names can vary along different datasets e.g. "img" or "image", "label" or "labels". Additionally, if the label column is of [ClassLabel](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.ClassLabel) type, we will also see the names of labels.
"""

# Note this dataset has
partition.features

"""### Indexing

To see the first sample of the partition, we can index it like a Python list.
"""

partition[0]

"""Then we can additionally choose the specific column."""

partition[0]["label"]

"""We can also use slicing (take a few samples). Let's take the first 3 samples of the first partition:"""

partition[:3]

"""We get a dictionary where the keys are the names of the columns and the values are list of the corresponding values of each row of the dataset. So to take the first 3 labels we can do:"""

partition[:3]["label"]

"""Note that the indexing by column first is also possible but discouraged because the whole column will be loaded into the memory."""

partition["label"][:3]

"""You can also select a subset of the dataset and keep the same type (dataset.Dataset) instead of receiving a dictionary of values."""

partition.select([0, 1, 2])

"""And this dataset contains the same samples as we saw before."""

partition.select([0, 1, 2])[:]

"""## Use with PyTorch/NumPy/TensorFlow

For more detailed instructions, go to:

* [how-to-use-with-pytorch](https://flower.ai/docs/datasets/how-to-use-with-pytorch.html)

* [how-to-use-with-numpy](https://flower.ai/docs/datasets/how-to-use-with-numpy.html)

* [how-to-use-with-tensorflow](https://flower.ai/docs/datasets/how-to-use-with-tensorflow.html)

### PyTorch

Transform the `Dataset` into the `DataLoader`, use the `PyTorch transforms` (`Compose` and all the others are possible).
"""

! pip install -q torch torchvision

from torch.utils.data import DataLoader
from torchvision.transforms import ToTensor

transforms = ToTensor()


def apply_transforms(batch):
    # For CIFAR-10 the "img" column contains the images we want to apply the transforms to
    batch["img"] = [transforms(img) for img in batch["img"]]
    return batch


partition_torch = partition.with_transform(apply_transforms)
dataloader = DataLoader(partition_torch, batch_size=64)

"""The `Dataloader` created this way does not return a `Tuple` when iterating over it but a `Dict` with the names of the columns as keys and features as values. Look below for an example."""

for batch in dataloader:
    print(f"Return type when iterating over a dataloader: {type(batch)}")
    print(batch["img"].shape)
    print(batch["label"].shape)
    break

"""### NumPy

NumPy can be used as input to the TensorFlow and scikit-learn models. The transformation is very simple.
"""

partition_np = partition.with_format("numpy")
X_train, y_train = partition_np["img"], partition_np["label"]

"""### TensorFlow Dataset

Transformation to TensorFlow Dataset is a one-liner.
"""

! pip install -q tensorflow

tf_dataset = partition.to_tf_dataset(
    columns="img", label_cols="label", batch_size=64, shuffle=True
)

"""## Final remarks

Congratulations, you now know the basics of Flower Datasets and are ready to perform basic dataset preparation for Federated Learning.

## Next

This is the first quickstart tutorial from the Flower Datasets series. See other tutorials:

* [Use Partitioners](https://flower.ai/docs/datasets/tutorial-use-partitioners.html)

* [Visualize Label Distribution](https://flower.ai/docs/datasets/tutorial-visualize-label-distribution.html)
"""